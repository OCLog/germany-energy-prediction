{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# Baseline XGBoost Example \u2014 with Plots\n\nThis notebook generates synthetic data (if missing), prepares features, runs a rolling time-series CV evaluation, plots fold MAE/RMSE and feature importances, trains a final model and saves it."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "import subprocess, sys\n",
        "from pathlib import Path\n",
        "ROOT = Path('0_LiteratureReview')\n",
        "CSV = ROOT / 'feature_template.csv'\n",
        "GEN = ROOT / 'generate_synthetic_data.py'\n",
        "if not CSV.exists():\n",
        "    # run generator using current python interpreter\n",
        "    if GEN.exists():\n",
        "        print('Generating synthetic CSV via', GEN)\n",
        "        subprocess.check_call([sys.executable, str(GEN)])\n",
        "    else:\n",
        "        raise FileNotFoundError('generate_synthetic_data.py not found under 0_LiteratureReview')\n",
        "print('CSV ready:', CSV.exists())\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load and prepare data\n",
        "import pandas as pd, numpy as np\n",
        "from sklearn.model_selection import TimeSeriesSplit\n",
        "from sklearn.metrics import mean_absolute_error, mean_squared_error\n",
        "from xgboost import XGBRegressor\n",
        "import joblib, math\n",
        "DF = pd.read_csv(str(CSV), parse_dates=['timestamp']).sort_values('timestamp').set_index('timestamp')\n",
        "DF['target'] = DF['price'].shift(-1)\n",
        "DF = DF.dropna(subset=['target'])\n",
        "features = [c for c in DF.columns if c != 'target' and pd.api.types.is_numeric_dtype(DF[c])]\n",
        "X = DF[features].ffill().bfill().fillna(0)\n",
        "y = DF['target'].values\n",
        "print('X shape', X.shape)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Rolling CV evaluation (collect metrics and feature importances)\n",
        "n_splits = 5\n",
        "tscv = TimeSeriesSplit(n_splits=n_splits)\n",
        "maes = []\n",
        "rmses = []\n",
        "fold_imps = []\n",
        "for fold, (tr, te) in enumerate(tscv.split(X), 1):\n",
        "    X_train, X_test = X.iloc[tr], X.iloc[te]\n",
        "    y_train, y_test = y[tr], y[te]\n",
        "    model = XGBRegressor(n_estimators=100, max_depth=6, learning_rate=0.1, random_state=42, verbosity=0)\n",
        "    model.fit(X_train, y_train)\n",
        "    pred = model.predict(X_test)\n",
        "    mae = mean_absolute_error(y_test, pred)\n",
        "    rmse = math.sqrt(mean_squared_error(y_test, pred))\n",
        "    maes.append(mae)\n",
        "    rmses.append(rmse)\n",
        "    # feature importance (gain-based, fallback to feature_importances_)\n",
        "    try:\n",
        "        imp = model.get_booster().get_score(importance_type='gain')\n",
        "        # convert dict to array aligned with features\n",
        "        imp_arr = [imp.get(f, 0.0) for f in [f'f{i}' for i in range(len(features))]]\n",
        "    except Exception:\n",
        "        # XGB sklearn API\n",
        "        imp_arr = list(model.feature_importances_)\n",
        "    fold_imps.append(imp_arr)\n",
        "    print(f'Fold {fold}: MAE={mae:.4f}, RMSE={rmse:.4f}')\n",
        "print('\\nCV Mean MAE={:.4f}, RMSE={:.4f}'.format(np.mean(maes), np.mean(rmses)))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Plot fold MAE/RMSE and aggregate feature importance\n",
        "import matplotlib.pyplot as plt\n",
        "plt.style.use('seaborn-v0_8')\n",
        "fig, ax = plt.subplots(1,2, figsize=(12,4))\n",
        "ax[0].plot(range(1, len(maes)+1), maes, marker='o', label='MAE')\n",
        "ax[0].plot(range(1, len(rmses)+1), rmses, marker='o', label='RMSE')\n",
        "ax[0].set_xlabel('CV Fold')\n",
        "ax[0].set_xticks(range(1, len(maes)+1))\n",
        "ax[0].set_ylabel('Error')\n",
        "ax[0].legend()\n",
        "ax[0].set_title('Fold MAE and RMSE')\n",
        "# Aggregate feature importances across folds (mean)\n",
        "import numpy as _np\n",
        "imp_matrix = _np.array(fold_imps)\n",
        "mean_imp = _np.mean(imp_matrix, axis=0)\n",
        "feat_order = _np.argsort(mean_imp)[::-1]\n",
        "top_n = min(20, len(features))\n",
        "top_idx = feat_order[:top_n]\n",
        "ax[1].barh([features[i] for i in top_idx[::-1]], mean_imp[top_idx[::-1]])\n",
        "ax[1].set_title('Mean Feature Importance (top {})'.format(top_n))\n",
        "plt.tight_layout()\n",
        "plt.show()\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Train final model on full data and save\n",
        "final = XGBRegressor(n_estimators=200, max_depth=6, learning_rate=0.05, random_state=42, verbosity=0)\n",
        "final.fit(X, y)\n",
        "joblib.dump({'model': final, 'features': features}, str(ROOT / 'baseline_model.pkl'))\n",
        "print('Saved final model to', str(ROOT / 'baseline_model.pkl'))\n"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python (germany-venv .venv)",
      "language": "python",
      "name": "germany-venv"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}